{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "res_df = pd.read_csv('../datasets/ams_order_results.csv.gz')\n",
    "cluster_df = pd.read_csv('../datasets/clustering.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.SaltRemover import SaltRemover\n",
    "from rdkit.Chem.FilterCatalog import *\n",
    "\n",
    "FP_radius=2\n",
    "FP_size=1024\n",
    "saltRemover = SaltRemover(defnFilename='../datasets/raw/Salts.txt')\n",
    "rdkit_mols = res_df['rdkit SMILES'].astype(str).apply((lambda x: Chem.MolFromSmiles(x)))\n",
    "rdkit_mols = rdkit_mols.apply((lambda x: saltRemover.StripMol(x)))\n",
    "res_df['rdkit SMILES'] = rdkit_mols.apply((lambda x: Chem.MolToSmiles(x)))\n",
    "res_df['1024 MorganFP Radius 2'] = rdkit_mols.apply((lambda x: AllChem.GetMorganFingerprintAsBitVect(x, \n",
    "                                                                                       radius=FP_radius, \n",
    "                                                                                       nBits=FP_size).ToBitString()))\n",
    "\n",
    "params = FilterCatalogParams()\n",
    "params.AddCatalog(FilterCatalogParams.FilterCatalogs.PAINS_A)\n",
    "params.AddCatalog(FilterCatalogParams.FilterCatalogs.PAINS_B)\n",
    "params.AddCatalog(FilterCatalogParams.FilterCatalogs.PAINS_C)\n",
    "pains_catalog = FilterCatalog(params)\n",
    "\n",
    "res_df['PAINS Filter'] = rdkit_mols.apply((lambda x: not pains_catalog.HasMatch(x))).astype(int)\n",
    "res_df.to_csv('../datasets/ams_order_results.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_df['Molecule ID'] = res_df['Structure_ID']\n",
    "res_df['SMSSF ID'] = res_df['SMSF']\n",
    "res_df['Index ID'] = np.arange(res_df.shape[0])\n",
    "cluster_df = cluster_df.iloc[:-1041,:]\n",
    "cluster_df = pd.concat([cluster_df, res_df[cluster_df.columns.tolist()]])\n",
    "cluster_df['Index ID'] = np.arange(cluster_df.shape[0])\n",
    "cluster_df.to_csv('../datasets/clustering.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "res_df = pd.read_csv('../datasets/ams_order_results.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df['Replicate1 Filter >= 50.0'] = (res_df['Replicate1'] >= 50.0).astype(int)\n",
    "res_df['Replicate2 Filter >= 50.0'] = (res_df['Replicate2'] >= 50.0).astype(int)\n",
    "res_df['Hit'] = (res_df['Replicate1 Filter >= 50.0'].astype(bool) & res_df['Replicate2 Filter >= 50.0'].astype(bool) & res_df['PAINS Filter'].astype(bool)).astype(int)\n",
    "\n",
    "res_df = res_df[res_df.columns.tolist()[:-3] + ['Replicate1 Filter >= 50.0', 'Replicate2 Filter >= 50.0', 'PAINS Filter']]\n",
    "res_df.to_csv('../datasets/ams_order_results.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "res_df = pd.read_csv('../datasets/ams_order_results.csv.gz')\n",
    "res_df = res_df[res_df.columns.tolist()[:-4] + ['Replicate1 Filter >= 50.0', 'Replicate2 Filter >= 50.0', 'PAINS Filter', 'Hit']]\n",
    "res_df.to_csv('../datasets/ams_order_results.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moeman\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "res_df = pd.read_csv('../datasets/ams_order_results.csv.gz')\n",
    "train_df = pd.read_csv('../datasets/folds/training_df_single_fold_with_clustering.csv.gz')\n",
    "cluster_df = pd.read_csv('../datasets/clustering.csv.gz')\n",
    "X = np.vstack([np.fromstring(x, 'u1') - ord('0') for x in cluster_df['1024 MorganFP Radius 2']]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_2 = np.memmap('../datasets/prospective_clustering/cluster_assigment_vector_0.2.dat', \n",
    "                      mode='r', dtype='int32', shape=(cluster_df.shape[0],))\n",
    "cluster_2l = np.memmap('../datasets/prospective_clustering/cluster_leader_idx_vector_0.2.dat', \n",
    "                      mode='r', dtype='int32', shape=(cluster_df.shape[0],))\n",
    "cluster_3 = np.memmap('../datasets/prospective_clustering/cluster_assigment_vector_0.3.dat', \n",
    "                      mode='r', dtype='int32', shape=(cluster_df.shape[0],))\n",
    "cluster_3l = np.memmap('../datasets/prospective_clustering/cluster_leader_idx_vector_0.3.dat', \n",
    "                      mode='r', dtype='int32', shape=(cluster_df.shape[0],))\n",
    "cluster_4 = np.memmap('../datasets/prospective_clustering/cluster_assigment_vector_0.4.dat', \n",
    "                      mode='r', dtype='int32', shape=(cluster_df.shape[0],))\n",
    "cluster_4l = np.memmap('../datasets/prospective_clustering/cluster_leader_idx_vector_0.4.dat', \n",
    "                      mode='r', dtype='int32', shape=(cluster_df.shape[0],))\n",
    "\n",
    "train_df['BT_0.2 ID'] = cluster_2[:-res_df.shape[0]]\n",
    "res_df['BT_0.2 ID'] = cluster_2[-res_df.shape[0]:]\n",
    "train_df['BT_0.2 Leader'] = cluster_2l[:-res_df.shape[0]]\n",
    "res_df['BT_0.2 Leader'] = cluster_2l[-res_df.shape[0]:]\n",
    "\n",
    "train_df['BT_0.3 ID'] = cluster_3[:-res_df.shape[0]]\n",
    "res_df['BT_0.3 ID'] = cluster_3[-res_df.shape[0]:]\n",
    "train_df['BT_0.3 Leader'] = cluster_3l[:-res_df.shape[0]]\n",
    "res_df['BT_0.3 Leader'] = cluster_3l[-res_df.shape[0]:]\n",
    "\n",
    "train_df['BT_0.4 ID'] = cluster_4[:-res_df.shape[0]]\n",
    "res_df['BT_0.4 ID'] = cluster_4[-res_df.shape[0]:]\n",
    "train_df['BT_0.4 Leader'] = cluster_4l[:-res_df.shape[0]]\n",
    "res_df['BT_0.4 Leader'] = cluster_4l[-res_df.shape[0]:]\n",
    "\n",
    "train_df.to_csv('../datasets/folds/training_df_single_fold_with_clustering.csv.gz', index=False)\n",
    "res_df.to_csv('../datasets/ams_order_results.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((339827,), (199697,), (88390,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cluster_2).shape, np.unique(cluster_3).shape, np.unique(cluster_4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11290322580645161"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.jaccard(X[135150], X[136369])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phits = res_df[res_df['Hit'] == 1]\n",
    "uhits = res_df[res_df['Hit'] == 1]['BT_0.2 ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((412, 33), (351,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phits.shape, uhits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thits = train_df[train_df['PriA-SSB AS Activity'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "u_mat = np.memmap('../clustering/tmp/dissimilarity_matrix_428324_428324.dat', \n",
    "                       dtype='float16', mode='r', shape=(428324, 428324))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((427283, 427283), (427283, 1024), (1024, 427283), (1024, 1024))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = dis_mat[:427283,:427283]\n",
    "B = dis_mat[:427283,427283:]\n",
    "C = dis_mat[427283:,:427283]\n",
    "D = dis_mat[427283:,427283:]\n",
    "A.shape, B.shape, C.shape, D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mat[:427283,:427283] = A\n",
    "u_mat.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mat[:427283,427283+17:] = B\n",
    "u_mat.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mat[427283+17:,:427283] = C\n",
    "u_mat.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mat[427283+17:,427283+17:] = D\n",
    "u_mat.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto_dissimilarity(X, Y, X_batch_size=50, Y_batch_size=50):\n",
    "    n_features = X.shape[-1]\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(-1, n_features)\n",
    "    if Y.ndim == 1:\n",
    "        Y = Y.reshape(-1, n_features)    \n",
    "    tan_sim = []\n",
    "    X_total_batches = X.shape[0] // X_batch_size + 1\n",
    "    Y_total_batches = Y.shape[0] // Y_batch_size + 1\n",
    "    for X_batch_i in range(X_total_batches):\n",
    "        X_start_idx = X_batch_i*X_batch_size\n",
    "        X_end_idx = min((X_batch_i+1)*X_batch_size, X.shape[0])\n",
    "        X_batch = X[X_start_idx:X_end_idx,:]\n",
    "        for Y_batch_i in range(Y_total_batches):\n",
    "            Y_start_idx = Y_batch_i*Y_batch_size\n",
    "            Y_end_idx = min((Y_batch_i+1)*Y_batch_size, Y.shape[0])\n",
    "            Y_batch = Y[Y_start_idx:Y_end_idx,:]\n",
    "            \n",
    "            # adapted from: https://github.com/deepchem/deepchem/blob/2531eca8564c1dc68910d791b0bcd91fd586afb9/deepchem/trans/transformers.py#L752\n",
    "            numerator = np.dot(X_batch, Y_batch.T).flatten() # equivalent to np.bitwise_and(X_batch, Y_batch), axis=1)\n",
    "            denominator = n_features - np.dot(1-X_batch, (1-Y_batch).T).flatten() # np.sum(np.bitwise_or(X_rep, Y_rep), axis=1)\n",
    "            \n",
    "            tan_sim.append(numerator / denominator)\n",
    "    tan_sim = np.hstack(tan_sim)\n",
    "    return 1.0 - tan_sim\n",
    "\n",
    "k = tanimoto_dissimilarity(X, Y)\n",
    "k = k.reshape(428324, 17).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mat[427283:427283+17,:] = k\n",
    "u_mat.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mat[:,427283:427283+17] = k.T\n",
    "u_mat.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del u_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
